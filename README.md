# Word embedding using pretrained model at gensim

gensim을 이용해서 Word embedding을 진행을 해보았습니다. 보통 Word embedding을 스스로 정하고 모델링 돌리는 경우가 있습니다. 그러나 google, twitter 등에서 pre-trained 된 모델을 직접 끌었는 경우가 있습니다. 단순히 언어 모델에서 쓸 수 있을 뿐만 아니라 문자형 변수를 숫자형 변수로 전환하는데 있어 One-hot-encoding의 대체로 쓸 수 있지 않을까 생각합니다.
